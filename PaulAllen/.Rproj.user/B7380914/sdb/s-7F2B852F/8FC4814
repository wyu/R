{
    "contents" : "library(plyr)\nlibrary(reshape2)\nrequire(RgoogleMaps)\nrequire(sp)\nlibrary(dismo)\n\nsource(\"/home/wyu/Projects/R/PaulAllen/prepareData.r\")\n\ntweets = prepareData(\"/home/wyu/Projects/R/PaulAllen/phailin_tweets.csv\");\n\n# twits   = read.csv(\"/home/wyu/Projects/R/PaulAllen/phailin_tweets.csv\" ,stringsAsFactors=FALSE) \n# ## split the time stamp into separate columns\n# date    = data.frame(do.call('rbind', strsplit(as.character(twits$Time),'/',fixed=TRUE))); \n# hr.min  = data.frame(do.call('rbind', strsplit(as.character(date$X3),' ',fixed=TRUE))); \n# min.sec = data.frame(do.call('rbind', strsplit(as.character(hr.min$X2),':',fixed=TRUE))); \n# time    = cbind(date[,c(1,2)], hr.min[,1], min.sec)\n# colnames(time) = c('Month','Day','Hour','Min','Sec')\n# twits = cbind(twits, time)\n# rm(date, hr.min, min.sec, time)\n\n# counts the rows by date\ncounts.day = aggregate(id~Day, data=tweets, length)\ncounts.min = aggregate(id~Day+Min, data=tweets, length)\nplot(counts.day)\nplot(counts.min)\n\n# # reformat the hash tags\n# co.Gopalpur = as.matrix(geocode(\"Gopalpur, India\")[  ,c('longitude','latitude')])\n# co.Mumbai   = as.matrix(geocode(\"Mumbai, India\")[    ,c('longitude','latitude')])\n# co.NewDelhi = as.matrix(geocode(\"New  Delhi, India\")[,c('longitude','latitude')])\n# \n# twits$HashTag=NA; twits$fromMumbai=NA; twits$fromGopalpur=NA; twits$NewDelhi=NA\n# tws = list(); k=0;\n# for (i in seq(1:dim(twits)[1])) \n# {\n#   # populate the distances\n#   if (is.na(twits[i,]$Tweet_GPS_long)==F&is.na(twits[i,]$Tweet_GPS_lat)==F)\n#   {\n#     co = matrix(c(twits[i,]$Tweet_GPS_long, twits[i,]$Tweet_GPS_lat), ncol=2);\n#     twits[i,]$fromNewDelhi=spDistsN1(co, co.NewDelhi[1,], longlat=TRUE)/1.6\n#     twits[i,]$fromMumbai  =spDistsN1(co, co.Mumbai[  1,], longlat=TRUE)/1.6\n#     twits[i,]$fromGopalpur=spDistsN1(co, co.Gopalpur[1,], longlat=TRUE)/1.6\n#   }\n#   htags=strsplit(twits$Hashtags_In_Text[i], ',');\n#   for (j in seq(1:length(htags[[1]])))\n#   {\n#     row = twits[i,];\n#     k   = k+1;\n#     row$HashTag = tolower(htags[[1]][j]);\n#     tws[[k]] = row\n#   }  \n# }\n# tweets = do.call(rbind, tws);\n# tweets$HashTag = as.factor(tweets$HashTag)\n# tweets$Month   = as.factor(tweets$Month)\n# tweets$Day     = as.factor(tweets$Day)\n# tweets$Hour    = as.factor(tweets$Hour)\n# tweets$Min     = as.factor(tweets$Min)\n# \n# rm(row, i,j,k, tws, htags)\n     \n# data inventory\nftable(tweets[c(\"HashTag\", \"Month\")])\n\n# the top 10 tags\nt10 = c('#phailin','#cyclonephailin','#odisha','#india','#cyclone','#news','#andhrapradesh','#phailinfury','#bhubaneswar','#gopalpur','#nari')\n\ntweets10 = droplevels(subset(tweets, HashTag %in% t10));\nftable(tweets10[c(\"HashTag\", \"Day\")])\nftable(tweets10[c(\"HashTag\")])\n\n# subset without re-tweet\nnoretweets = droplevels(subset(tweets, Is_Retweet==0));\nnoGPS      = droplevels(subset(noretweets, is.na(Tweet_GPS_lat)|is.na(Tweet_GPS_long)));\nGPS        = droplevels(subset(noretweets, is.na(Tweet_GPS_lat)==F&is.na(Tweet_GPS_long)==F));\n\nftable(droplevels(subset(noretweets, HashTag %in% t10))[c(\"HashTag\", \"Day\")])\n",
    "created" : 1391920913672.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4165454508",
    "id" : "8FC4814",
    "lastKnownWriteTime" : 1393023365,
    "path" : "~/Projects/R/PaulAllen/task1.r",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_source"
}