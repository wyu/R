twits = cbind(twits, time)
# counts the rows by date
counts.day = aggregate(id~Day, data=twits, length)
strsplit(twits$Hashtags_In_Text[i], ',')
strsplit(twits$Hashtags_In_Text[i], ',')[1]
strsplit(twits$Hashtags_In_Text[i], ',')[[1]]
class(strsplit(twits$Hashtags_In_Text[i], ','))
length(strsplit(twits$Hashtags_In_Text[i], ','))
j=strsplit(twits$Hashtags_In_Text[i], ',')
fix(j)
j[1,1]
dim(j)
j[1]
j[2]
data.frame(j)
data.frame(j)[1,1]
data.frame(j)[1,2]
data.frame(j)[2,2]
data.frame(j)[2,1]
j=data.frame(strsplit(twits$Hashtags_In_Text[i], ','));
j
counts.hr  = aggregate(id~Day+Hour, data=twits, length)
View(counts.hr)
unique(twits$Hour)
View(twits)
counts.min = aggregate(id~Day+Min, data=twits, length)
View(counts.min)
plot(counts.min)
j=strsplit(twits$Hashtags_In_Text[i], ',')
dim(j)
length(j)
class(j)
j(1)
j[1]
j[[1]]
j[[1]]
j[[1]][1]
j[[1]][2]
length(j[[1]])
length(j[[2]])
rm(date, hr.min, min.sec, time)
htags=strsplit(twits$Hashtags_In_Text[i], ',');
seq(1:length(htags[[1]]))
row = twits[i];
View(row)
row = twits[i,];
View(row)
row$HashTag = htags[[1]][j]
htags[[1]][j]
j=1
htags[[1]][j]
row$HashTag = htags[[1]][j]
View(row)
order
k=0;
k++
1
k = k+1;
k+=1
k
tws[[k]] = row
tws = list();
tws[[k]] = row
twits$HashTag=NA;
tws = list(); k=0;
for (i in seq(1:dim(twits)[1])
{
htags=strsplit(twits$Hashtags_In_Text[i], ',');
for (j in seq(1:length(htags[[1]])))
{
row = twits[i,];
k = k+1;
row$HashTag = htags[[1]][j]
tws[[k]] = row
}
}
seq(1:dim(twits)[1])
twits$HashTag=NA;
tws = list(); k=0;
for (i in seq(1:dim(twits)[1]))
{
htags=strsplit(twits$Hashtags_In_Text[i], ',');
for (j in seq(1:length(htags[[1]])))
{
row = twits[i,];
k = k+1;
row$HashTag = htags[[1]][j]
tws[[k]] = row
}
}
tweets = do.call(rbind, tws);
rm(row, i,j,k, tws, htags, htag)
class(tweets$HashTag)
tweets$HashTag = as.factor(tweets$HashTag)
class(tweets$HashTag)
tweets$Month = as.factor(tweets$Month)
tweets$HashTag = as.factor(tweets$HashTag)
tweets$Month   = as.factor(tweets$Month)
tweets$Day     = as.factor(tweets$Day)
tweets$Hour    = as.factor(tweets$Hour)
tweets$Min     = as.factor(tweets$Min)
counts.day = aggregate(id~Day, data=twits, length)
View(counts.day)
ftable(tweets$HashTag, tweets$id)
unique(tweets$HashTag)
?ftable
ftable(mtcars[c("cyl", "vs", "am", "gear")])
View(tweets)
ftable(tweets[c("HashTag", "Month")])
t10 = c('#phailin','#cyclonephailin','#odisha','#india','#cyclone','#news','#andhrapradesh','#phailinfury','#bhubaneswar','#gopalpur','#nari')
tweets10 = subset(tweets, HashTag %in% t10)
View(tweets10)
?lowercase
twits   = read.csv("/home/wyu/Projects/R/PaulAllen/phailin_tweets.csv" ,stringsAsFactors=FALSE)
## split the time stamp into separate columns
date    = data.frame(do.call('rbind', strsplit(as.character(twits$Time),'/',fixed=TRUE)));
hr.min  = data.frame(do.call('rbind', strsplit(as.character(date$X3),' ',fixed=TRUE)));
min.sec = data.frame(do.call('rbind', strsplit(as.character(hr.min$X2),':',fixed=TRUE)));
time    = cbind(date[,c(1,2)], hr.min[,1], min.sec)
colnames(time) = c('Month','Day','Hour','Min','Sec')
twits = cbind(twits, time)
rm(date, hr.min, min.sec, time)
# reformat the hash tags
twits$HashTag=NA;
tws = list(); k=0;
for (i in seq(1:dim(twits)[1]))
{
htags=strsplit(twits$Hashtags_In_Text[i], ',');
for (j in seq(1:length(htags[[1]])))
{
row = twits[i,];
k = k+1;
row$HashTag = tolower(htags[[1]][j]);
tws[[k]] = row
}
}
tweets = do.call(rbind, tws);
tweets$HashTag = as.factor(tweets$HashTag)
tweets$Month   = as.factor(tweets$Month)
tweets$Day     = as.factor(tweets$Day)
tweets$Hour    = as.factor(tweets$Hour)
tweets$Min     = as.factor(tweets$Min)
rm(row, i,j,k, tws, htags, htag)
t10 = c('#phailin','#cyclonephailin','#odisha','#india','#cyclone','#news','#andhrapradesh','#phailinfury','#bhubaneswar','#gopalpur','#nari')
tweets10 = subset(tweets, HashTag %in% t10)
ftable(tweets10[c("HashTag", "Month")])
tweets10 = droplevels(subset(tweets, HashTag %in% t10));
ftable(tweets10[c("HashTag", "Month")])
ftable(tweets10[c("HashTag", "Day")])
View(tweets)
unique(tweets$Is_Retweet)
noretweets = droplevels(subset(tweets, Is_Retweet==0));
View(tweets)
colnames(tweets)
noGPS = droplevels(subset(noretweets, is.na(Tweet_GPS_lat)|is.na(Tweet_GPS_long));
noGPS = droplevels(subset(noretweets, is.na(Tweet_GPS_lat)|is.na(Tweet_GPS_long)));
?require
require(RgoogleMaps)
install.packages("RgoogleMaps")
require(RgoogleMaps)
require(RgoogleMaps)
#define the part of the world you want to plot. Here the area around my former home.
lat_c<-51.47393
lon_c<-7.22667
bb<-qbbox(lat = c(lat_c[1]+0.01, lat_c[1]-0.01), lon = c(lon_c[1]+0.03, lon_c[1]-0.03))
OSM.map<-GetMap.OSM(lonR=bb$lonR, latR=bb$latR, scale = 20000, destfile="bochum.png")
image(OSM.map)
?image
OSM.map
image(OSM.map)
require(graphics)
image(OSM.map)
lat=c(48,64)
lon=c(-140,-110)
center=c(mean(lat), mean(lon))
zoom=5
terrmap=GetMap(center=center, zoom=zoom, maptype="terrain", destfile = "terrain.png")
tmp <- PlotOnStaticMap(terrmap, lat = NA, lon = NA,
col=c( 'red','blue','green'), add=FALSE)
library(sp)
installed.packages("sp")
install.packages("sp")
library(sp)
data("meuse", package = "sp", envir = environment())
m<-bubbleMap(meuse,zcol='zinc');
install.packages("rgdal")
View(tweets)
?sp
require(sp)
?coordinates
install.packages("dismo")
library(dismo)
geocode("Seattle, WA, USA")
df$geocode_string = "Seattle, WA, USA"
df
?geocode
geocode("Gopalpur, India")
geocode("New  Delhi, India")
geocode("New  Delhi, Delhi, India")
geocode("New  Delhi, India")
?spDistsN1
?SpatialPointsDataFrame
twits[,c()]
colnames(twits)
twits[,c('Tweet_GPS_lat','Tweet_GPS_long')]
j=twits[,c('Tweet_GPS_lat','Tweet_GPS_long')]
j=as.matrix(twits[,c('Tweet_GPS_lat','Tweet_GPS_long')])
View(j)
km <- spDistsN1(j, c(20.8, 86.9), longlat=TRUE)
km <- spDistsN1(j, as.matrix(c(20.8, 86.9)), longlat=TRUE)
km <- spDistsN1(j, t(c(20.8, 86.9)), longlat=TRUE)
km <- spDistsN1(j, j[4994,], longlat=TRUE)
ll <- matrix(c(5, 6, 60, 60), ncol=2)
km <- spDistsN1(ll, ll[1,], longlat=TRUE)
km
class(ll)
class(j)
class(ll[1,])
ll[1,]
j[1,]
j[4998,]
class(j[4998,])
km <- spDistsN1(j, j[4998,], longlat=TRUE)
km <- spDistsN1(j, as.numeric(j[4998,]), longlat=TRUE)
km <- spDistsN1(j, ll[1,], longlat=TRUE)
twits$HashTag=NA; twits$fromMubai=NA; twits$fromGopalpur=NA; twits$NewDelhi=NA
i=4998
co = matrix(c(twits[i,]$Tweet_GPS_long, twits[i,]$Tweet_GPS_lat), ncol=2)
co
geocode("Gopalpur, India")
class(geocode("Gopalpur, India"))
as.matrix(geocode("Gopalpur, India")[,c('longitude','latitude')])
class(as.matrix(geocode("Gopalpur, India")[,c('longitude','latitude')]))
co.Gopalpur = as.matrix(geocode("Gopalpur, India")[  ,c('longitude','latitude')])
co.Mumbai   = as.matrix(geocode("Mumbai, India")[    ,c('longitude','latitude')])
co.NewDelhi = as.matrix(geocode("New  Delhi, India")[,c('longitude','latitude')])
km <- spDistsN1(ll, co.NewDelhi, longlat=TRUE)
km <- spDistsN1(ll, as.list(co.NewDelhi), longlat=TRUE)
km <- spDistsN1(ll, t(co.NewDelhi), longlat=TRUE)
t(co.NewDelhi)
class(t(co.NewDelhi))
km <- spDistsN1(ll, as.numeric(co.NewDelhi), longlat=TRUE)
km <- spDistsN1(ll, co.NewDelhi[1,], longlat=TRUE)
km
km <- spDistsN1(ll, co.NewDelhi[1,], longlat=FALSE)
km
km <- spDistsN1(co, co.NewDelhi[1,], longlat=FALSE)
km
spDistsN1(co, co.NewDelhi[1,], longlat=TRUE)
spDistsN1(matrix(c(twits[i,]$Tweet_GPS_long, twits[i,]$Tweet_GPS_lat), ncol=2), co.NewDelhi[1,], longlat=TRUE)
spDistsN1(matrix(c(twits[i,]$Tweet_GPS_long, twits[i,]$Tweet_GPS_lat), ncol=2), co.NewDelhi[1,], longlat=TRUE)/1.6
spDistsN1(co.Mumbai, co.NewDelhi, longlat=TRUE)
spDistsN1(co.Mumbai, co.NewDelhi[1,], longlat=TRUE)
View(twits)
co.NewDelhi = as.matrix(geocode("New  Delhi, India")[,c('longitude','latitude')])
View(co.NewDelhi)
library(plyr)
library(reshape2)
require(RgoogleMaps)
require(sp)
datfile="/home/wyu/Projects/R/PaulAllen/phailin_tweets.csv"
twits   = read.csv(datfile ,stringsAsFactors=TRUE)
## split the time stamp into separate columns
date    = data.frame(do.call('rbind', strsplit(as.character(twits$Time),'/',fixed=TRUE)));
hr.min  = data.frame(do.call('rbind', strsplit(as.character(date$X3),' ',fixed=TRUE)));
min.sec = data.frame(do.call('rbind', strsplit(as.character(hr.min$X2),':',fixed=TRUE)));
time    = cbind(date[,c(1,2)], hr.min[,1], min.sec)
colnames(time) = c('Month','Day','Hour','Min','Sec')
twits = cbind(twits, time)
# reformat the hash tags
co.Gopalpur = as.matrix(geocode("Gopalpur, India")[  ,c('longitude','latitude')])
co.Mumbai   = as.matrix(geocode("Mumbai, India")[    ,c('longitude','latitude')])
co.NewDelhi = as.matrix(geocode("New  Delhi, India")[,c('longitude','latitude')])
twits$HashTag=NA; twits$fromMumbai=NA; twits$fromGopalpur=NA; twits$NewDelhi=NA
twits$AcctGPS_lat=NA; twits$AcctGPS_long=NA
tws = list(); k=0;
for (i in seq(1:dim(twits)[1]))
{
# populate the distances
if (is.na(twits[i,]$Tweet_GPS_long)==F&is.na(twits[i,]$Tweet_GPS_lat)==F)
{
co = matrix(c(twits[i,]$Tweet_GPS_long, twits[i,]$Tweet_GPS_lat), ncol=2);
twits[i,]$fromNewDelhi=spDistsN1(co, co.NewDelhi[1,], longlat=TRUE)/1.6
twits[i,]$fromMumbai  =spDistsN1(co, co.Mumbai[  1,], longlat=TRUE)/1.6
twits[i,]$fromGopalpur=spDistsN1(co, co.Gopalpur[1,], longlat=TRUE)/1.6
}
else
{
co = geocode(twits[i,]$Twitter_User_Account_Location);
twits$AcctGPS_lat =co$latitude;
twits$AcctGPS_long=co$longitude;
}
htags=strsplit(twits$Hashtags_In_Text[i], ',');
for (j in seq(1:length(htags[[1]])))
{
row = twits[i,];
k   = k+1;
row$HashTag = tolower(htags[[1]][j]);
tws[[k]] = row
}
}
tws = list(); k=0;
for (i in seq(1:dim(twits)[1]))
{
# populate the distances
if (is.na(twits[i,]$Tweet_GPS_long)==F&is.na(twits[i,]$Tweet_GPS_lat)==F)
{
co = matrix(c(twits[i,]$Tweet_GPS_long, twits[i,]$Tweet_GPS_lat), ncol=2);
twits[i,]$fromNewDelhi=spDistsN1(co, co.NewDelhi[1,], longlat=TRUE)/1.6
twits[i,]$fromMumbai  =spDistsN1(co, co.Mumbai[  1,], longlat=TRUE)/1.6
twits[i,]$fromGopalpur=spDistsN1(co, co.Gopalpur[1,], longlat=TRUE)/1.6
}
else
{
co = geocode(twits[i,]$Twitter_User_Account_Location);
twits[i,]$AcctGPS_lat =co$latitude;
twits[i,]$AcctGPS_long=co$longitude;
}
htags=strsplit(twits$Hashtags_In_Text[i], ',');
for (j in seq(1:length(htags[[1]])))
{
row = twits[i,];
k   = k+1;
row$HashTag = tolower(htags[[1]][j]);
tws[[k]] = row
}
}
co
co[1]
co[1,]
twits[i,]$AcctGPS_lat =co[1,]$latitude;
twits[i,]$AcctGPS_long=co[1,]$longitude;
tws = list(); k=0;
for (i in seq(1:dim(twits)[1]))
{
# populate the distances
if (is.na(twits[i,]$Tweet_GPS_long)==F&is.na(twits[i,]$Tweet_GPS_lat)==F)
{
co = matrix(c(twits[i,]$Tweet_GPS_long, twits[i,]$Tweet_GPS_lat), ncol=2);
twits[i,]$fromNewDelhi=spDistsN1(co, co.NewDelhi[1,], longlat=TRUE)/1.6
twits[i,]$fromMumbai  =spDistsN1(co, co.Mumbai[  1,], longlat=TRUE)/1.6
twits[i,]$fromGopalpur=spDistsN1(co, co.Gopalpur[1,], longlat=TRUE)/1.6
}
else
{
co = geocode(twits[i,]$Twitter_User_Account_Location);
twits[i,]$AcctGPS_lat =co[1,]$latitude;
twits[i,]$AcctGPS_long=co[1,]$longitude;
}
htags=strsplit(twits$Hashtags_In_Text[i], ',');
for (j in seq(1:length(htags[[1]])))
{
row = twits[i,];
k   = k+1;
row$HashTag = tolower(htags[[1]][j]);
tws[[k]] = row
}
}
twits$Hashtags_In_Text[i]
htags=strsplit(as.character(twits$Hashtags_In_Text[i]), ',');
tws = list(); k=0;
for (i in seq(1:dim(twits)[1]))
{
# populate the distances
if (is.na(twits[i,]$Tweet_GPS_long)==F&is.na(twits[i,]$Tweet_GPS_lat)==F)
{
co = matrix(c(twits[i,]$Tweet_GPS_long, twits[i,]$Tweet_GPS_lat), ncol=2);
twits[i,]$fromNewDelhi=spDistsN1(co, co.NewDelhi[1,], longlat=TRUE)/1.6
twits[i,]$fromMumbai  =spDistsN1(co, co.Mumbai[  1,], longlat=TRUE)/1.6
twits[i,]$fromGopalpur=spDistsN1(co, co.Gopalpur[1,], longlat=TRUE)/1.6
}
else
{
co = geocode(twits[i,]$Twitter_User_Account_Location);
twits[i,]$AcctGPS_lat =co[1,]$latitude;
twits[i,]$AcctGPS_long=co[1,]$longitude;
}
htags=strsplit(as.character(twits$Hashtags_In_Text[i]), ',');
for (j in seq(1:length(htags[[1]])))
{
row = twits[i,];
k   = k+1;
row$HashTag = tolower(htags[[1]][j]);
tws[[k]] = row
}
}
View(twits)
unique(twits$Twitter_User_Account_Location)
library(plyr)
library(reshape2)
require(RgoogleMaps)
require(sp)
source("/home/wyu/Projects/R/PaulAllen/prepareData.r")
tweets = prepareData("/home/wyu/Projects/R/PaulAllen/phailin_tweets.csv");
?geocode
library(dismo)
?geocode
tweets = prepareData("/home/wyu/Projects/R/PaulAllen/phailin_tweets.csv");
View(tweets)
View(tweets)
View(tweets)
unique(tweets$HashTag)
library(plyr)
library(reshape2)
require(RgoogleMaps)
require(sp)
library(dismo)
source("/home/wyu/Projects/R/PaulAllen/prepareData.r")
tweets = prepareData("/home/wyu/Projects/R/PaulAllen/phailin_tweets.csv");
counts.day = aggregate(id~Day, data=twits, length)
counts.min = aggregate(id~Day+Min, data=twits, length)
plot(counts.day)
counts.day = aggregate(id~Day, data=tweets, length)
counts.min = aggregate(id~Day+Min, data=tweets, length)
plot(counts.day)
plot(counts.min)
ftable(tweets[c("HashTag", "Month")])
# the top 10 tags
t10 = c('#phailin','#cyclonephailin','#odisha','#india','#cyclone','#news','#andhrapradesh','#phailinfury','#bhubaneswar','#gopalpur','#nari')
tweets10 = droplevels(subset(tweets, HashTag %in% t10));
ftable(tweets10[c("HashTag", "Day")])
noretweets = droplevels(subset(tweets, Is_Retweet==0));
noGPS      = droplevels(subset(noretweets, is.na(Tweet_GPS_lat)|is.na(Tweet_GPS_long)));
t10
View(tweets10)
ftable(tweets10[c("HashTag", "Day")])
ftable(tweets10[c("HashTag")])
ftable(tweets10[c("HashTag", "Day", "Min")])
View(tweets)
noretweets = droplevels(subset(tweets, Is_Retweet==0));
View(tweets)
GPS        = droplevels(subset(noretweets, is.na(Tweet_GPS_lat)==F&is.na(Tweet_GPS_long)==F));
View(GPS)
ftable(noretweets[c("HashTag", "Day")])
ftable(droplevels(subset(noretweets, HashTag %in% t10))[c("HashTag", "Day")])
ftable(tweets[c("HashTag", "Month")])
ftable(tweets10[c("HashTag", "Day")])
ftable(droplevels(subset(noretweets, HashTag %in% t10))[c("HashTag", "Day")])
View(tweets)
install.packages("psych")
library(psych)
paired.r(.2,.3,.93,100)
$p
paired.r(.2,.3,.93,100)$p
paired.r
paired.r(.998,.997,.93,6)$p
paired.r(.998,.997,.93,7)$p
paired.r(.998,.997,.93,100)$p
paired.r(.998,.997,.93,100)
paired.r(.998,.97,.93,100)
paired.r(.998,.7,.93,100)
paired.r(.8,.7,.93,100)
cor.diff.test = function(r1, r2, n1, n2, alternative = c("two.sided", "less", "greater")) {
Z1 = 0.5 * log( (1+r1)/(1-r1) )
Z2 = 0.5 * log( (1+r2)/(1-r2) )
diff = Z1 - Z2
SEdiff = sqrt( 1 / (n1 - 3) + 1 / (n2 - 3))
diff.Z = diff / SEdiff
if (alternative == "less") {
return(pnorm(diff.Z, lower.tail=F))
} else if (alternative == "greater") {
return(pnorm(-diff.Z, lower.tail=F))
} else if (alternative == "two.sided") {
return(2 * pnorm( abs(diff.Z), lower.tail=F))
} else {
warning(paste("Invalid alterantive", alternative), domain=NA)
return(NA)
}
}
source('~/Projects/R/PaulAllen/cor.diff.test.r')
cor.diff.test(0.998, 0.997, 6, 7, "less")
cor.diff.test(0.998, 0.7, 6, 7, "less")
r1=0.998
r2=997
n1=6
n2=7
Z1 = 0.5 * log( (1+r1)/(1-r1) )
Z1
Z2 = 0.5 * log( (1+r2)/(1-r2) )
r2=0.997
Z2 = 0.5 * log( (1+r2)/(1-r2) )
Z2
diff = Z1-Z2
diff
SEdiff = sqrt( 1 / (n1 - 3) + 1 / (n2 - 3))
SEdiff
library(plyr)
diff.Z = diff / SEdiff
pnorm(diff.Z, lower.tail=F)
diffZ
diff.Z
pnorm(diff.Z, lower.tail=F)
pnorm
pnorm(0.55, lower.tail=F)
>pnorm
?pnorm
pnorm(0, lower.tail=F)
pnorm.C()
method(pnorm)
methods(pnorm)
pnorm
pnorm.External()
pnorm.External
pnorm.External
pnorm(0.55, lower.tail=F)
pnorm(0.25, lower.tail=F)
1521*0.05
p.adjust(0.05, method = "BH", 1521)
p.adjust(0.0005, method = "BH", 1521)
0.7605/0.005
0.7605/0.0005
?p.adjust
